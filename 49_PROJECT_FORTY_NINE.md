# Server Management for Analytics and Reporting

---

### **Directory Creation & Organization:**

1. Create a directory named "analytics_reports".
2. Inside "analytics_reports", create 12 subdirectories, each named after a month (e.g., "January", "February", etc.).
3. Inside each month’s directory, create files to represent daily report data (e.g., "report_day_1.csv", "report_day_2.csv").

---

### **Move and Rename Files:**

1. Move a report file (e.g., "report_day_1.csv") from one month's directory to another (e.g., from "January" to "February").
2. Rename a report file within a directory (e.g., rename "report_day_1.csv" to "final_report_day_1.csv") and verify the change by listing the contents of the directory.

---

### **Navigation & Listing Files:**

1. Navigate to the "analytics_reports" directory.
2. List the contents of the directory and verify the presence of all subdirectories for each month (e.g., "January", "February") and the relevant report files created.

---

### **File Permissions Management:**

1. Create a file named "config.txt" in the "analytics_reports" directory to store configuration settings for the analytics system (e.g., data source configurations).
2. Change the permissions of the file so that only the user has read, write, and execute permissions.
3. Verify the permission changes by listing the file's details.

---

### **Backup Files:**

1. Create a backup of a report file (e.g., "report_day_1.csv") by copying it to another backup directory.
2. Verify the backup operation by listing the contents of the backup directory.

---

### **Removing Files & Directories:**

1. Delete an outdated report file (e.g., "report_day_1.csv") in the "analytics_reports" directory that is no longer required.
2. Remove an empty subdirectory from one of the months' directories (e.g., remove the "March" directory if it’s empty).

---

### **Creating a Script for File Generation:**

1. Write a script that creates 100 unique report files (e.g., "report_1.csv", "report_2.csv") in the "analytics_reports" directory, simulating daily reports for analysis.

---

### **Exploring File History:**

1. View the command history to see the last 20 commands executed related to file management in the analytics environment.
2. Search the history for any command related to data manipulation, report generation, or backup.

---

### **System Monitoring:**

1. Check the system’s uptime to ensure the analytics services are continuously available for data processing.
2. View the system’s load and resource usage statistics, focusing on CPU, memory, and disk usage, to ensure the system can handle large-scale analytics processing.

---

### **Checking File Ownership and Permissions:**

1. Check the ownership and group of the "config.txt" file and verify whether they are correct, ensuring only authorized users can modify the analytics configuration.

---

### **Ping Test & Network Verification:**

1. Verify network connectivity by pinging remote analytics data sources or storage nodes to ensure data can be fetched and stored correctly.
2. Record the response times and verify that the network latency is acceptable for real-time analytics.

---

### **Search for Specific Files or Content:**

1. Search for a specific report file (e.g., "report_day_1.csv") within the "analytics_reports" directory.
2. Search for a specific string of text (e.g., "error") inside one of the report files to identify any issues in the generated data or reports.

---

### **Create a Directory for Each User:**

1. Create a directory for each user or team (e.g., "data_scientist_reports", "marketing_reports") to store their respective reports and data.
2. Assign appropriate permissions for each user/team to ensure secure access to the reports.

---

### **Creating a Script for Directory Cleanup:**

1. Write a script that deletes all empty subdirectories from the "analytics_reports" directory, ensuring that obsolete directories are removed from the system.

---

### **File Sorting & Management:**

1. Sort the report files by size (e.g., large reports that contain detailed analytics) and then list the files based on their size to optimize storage.
2. Create a report listing the largest and smallest files in the directory to manage large reports and archive unnecessary data.

---

### **File Type Identification:**

1. Identify and list specific types of files (e.g., CSV files, JSON files, or XML files) in the "analytics_reports" directory to manage the different report formats efficiently.
2. Filter report files based on their type to ensure proper handling and processing.

---

### **File Compression and Archive:**

1. Compress the "analytics_reports" directory into a single archive file to create a backup of all reports and configurations.
2. Verify the contents of the archive without extracting it, ensuring that all required reports are included in the backup.

---

### NOTE: Finally fetch all the project commands from history and create a detailed project report "your_name_rollname.md" and push it to git your git repository