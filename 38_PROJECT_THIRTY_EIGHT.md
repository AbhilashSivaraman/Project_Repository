# Server Management for Search Engine Server

---

### **Directory Creation & Organization:**

1. Create a directory named "search_engine_data".
2. Inside "search_engine_data", create 12 subdirectories, each named after a month (e.g., "January", "February", etc.).
3. Inside each monthâ€™s directory, create files that track search query logs and indexing data (e.g., "search_query_log_day_1.txt", "indexing_data_day_1.csv").

---

### **Move and Rename Files:**

1. Move a log file (e.g., "search_query_log_day_1.txt") from one month's directory to another (e.g., from "January" to "February").
2. Rename a file within a directory (e.g., rename "indexing_data_day_1.csv" to "indexing_data_day_1_updated.csv") and verify the change by listing the contents of the directory.

---

### **Navigation & Listing Files:**

1. Navigate to the "search_engine_data" directory.
2. List the contents of the directory and verify the presence of all month directories (e.g., "January", "February", etc.) and the log files created in the previous task.

---

### **File Permissions Management:**

1. Create a file named "search_engine_config.txt" in the "search_engine_data" directory.
2. Change the permissions of the file so that only the user has read, write, and execute permissions.
3. Verify the permission changes by listing the file's details.

---

### **Backup Files:**

1. Create a backup of a log file (e.g., "search_query_log_day_1.txt") by copying it to another directory (e.g., "backup").
2. Verify the copy operation by listing the contents of the backup directory.

---

### **Removing Files & Directories:**

1. Delete one of the log files in the "search_engine_data" directory (e.g., delete "search_query_log_day_1.txt").
2. Remove an empty subdirectory from one of the months' directories (e.g., remove the "March" directory if it's empty).

---

### **Creating a Script for File Generation:**

1. Write a script that creates 100 log files inside the "search_engine_data" directory, with each file representing a unique search query log or indexing data (e.g., "search_query_log_1.txt", "indexing_data_2.csv").

---

### **Exploring File History:**

1. View the command history to see the last 20 commands executed.
2. Search the history for any command related to search query log files or indexing data manipulation.

---

### **System Monitoring:**

1. Check the system's uptime to ensure the search engine server is running without interruptions.
2. View the system's load and resource usage statistics to verify the server can handle high search traffic and indexing requests.

---

### **Checking File Ownership and Permissions:**

1. Check the ownership and group of the "search_engine_config.txt" file and verify whether they are correct for managing the configuration files of the search engine.

---

### **Ping Test & Network Verification:**

1. Verify network connectivity by pinging the web crawler or external APIs the search engine interacts with.
2. Record the response times and verify the connectivity between the search engine server and the external services it communicates with.

---

### **Search for Specific Files or Content:**

1. Search for a specific log file within the "search_engine_data" directory by its name (e.g., search for "search_query_log_day_15.txt").
2. Search for a specific string of text (e.g., "query failed") inside one of the log files in the directory.

---

### **Create a Directory for Each Search Engine Instance:**

1. Create a directory for each search engine instance (e.g., "search_instance_1", "search_instance_2") and assign appropriate permissions to store configuration files, logs, and indexing data for each instance.

---

### **Creating a Script for Directory Cleanup:**

1. Write a script that deletes all empty subdirectories from the "search_engine_data" directory to keep the file structure organized and ensure that unused directories are removed.

---

### **File Sorting & Management:**

1. Sort log files in the "search_engine_data" directory by size and then list the files based on their size to help in identifying large query logs or indexing data.
2. Create a report listing the largest and smallest log files in the directory to identify which logs are taking up more space.

---

### **File Type Identification:**

1. Identify and list log files of a specific type (e.g., .txt, .csv) used for storing search queries, indexing reports, or crawl data in the "search_engine_data" directory.

---

### **File Compression and Archive:**

1. Compress the "search_engine_data" directory into a single archive file for backup purposes.
2. Verify the contents of the archive without extracting it to ensure it contains all necessary log files, query data, and indexing reports.

---

### NOTE: Finally fetch all the project commands from history and create a detailed project report "your_name_rollname.md" and push it to git your git repository